# ðŸ”„ Prompt Adaptation Across AI Models

## Overview
This document explains how to adapt structured prompts for different LLMs:
- **ChatGPT / GPT-4 / GPT-5 (OpenAI)**
- **Claude (Anthropic)**
- **Copilot (GitHub/OpenAI)**

All models interpret intent similarly, but they vary in:
- Input style (chat vs. inline)
- Context handling
- Sensitivity to formatting (Markdown, JSON, comments)

---

## ðŸ§  1. General Guidance

| Model | Ideal Input Style | Best For | Context Length | Markdown Support | JSON Fidelity |
|--------|------------------|-----------|----------------|------------------|----------------|
| **ChatGPT / GPT-5** | Full Markdown + JSON hybrid | Structured reasoning, coding, analysis | ~128k tokens | âœ… Excellent | âœ… Excellent |
| **Claude** | Concise Markdown with clearly scoped tasks | Explanations, documentation, summarization | 200k+ tokens | âœ… Excellent | âœ… Good |
| **Copilot** | Inline comments and short instructions | Code completion, refactoring | ~2â€“4k tokens | âš ï¸ Limited | âš ï¸ Limited |

---

## ðŸ§© 2. Example: Code Generation Prompt

### ðŸŸ¦ ChatGPT / GPT-5
```markdown
## Context
You are a Python engineer.

## Task
Write a function that:
- Loads a CSV
- Filters by a date range
- Returns summary statistics for numeric columns

## Constraints
- Use pandas only
- Assume column "timestamp" exists
- Return a pandas DataFrame

## Output Format
Provide only code inside a ```python``` block.

```
## ðŸŸ§ Claude

```markdown
(You are a Python engineer.)

Please write a concise, readable function that:
- Loads a CSV and filters rows by date range
- Calculates summary stats for numeric columns

Constraints:
- Use pandas only
- Column name: "timestamp"
- Return a DataFrame, no printed output

Output: Python code only.
```
## ðŸŸ© Copilot

```python
# Task: Load a CSV file and filter it by a date range.
# Requirements:
# - Use pandas only
# - Assume a 'timestamp' column
# - Return a DataFrame with summary statistics for numeric columns.

def summarize_csv(filepath, start_date, end_date)
    # your code here


```
## 3. Adaptation Rules Summary
| Principle                | ChatGPT                  | Claude                       | Copilot                        |
| ------------------------ | ------------------------ | ---------------------------- | ------------------------------ |
| **Structure**            | Multi-layer Markdown     | Compact Markdown             | Inline comments                |
| **Tone**                 | Instructional            | Conversational               | Directive                      |
| **Output Formatting**    | Use ``` blocks           | Use concise formatting       | Use code comments              |
| **Constraints Handling** | Very reliable            | Reliable with short phrasing | Limited, inferred from context |
| **Context Length**       | Large (multi-section OK) | Very large (long prompts OK) | Small (short context)          |
| **Best For**             | Deep reasoning & coding  | Documentation & design       | Inline coding help             |

## âš™ï¸ 4. TL;DR â€” Adaptation Summary

| Layer | Universal | ChatGPT/GPT | Claude | Copilot |
|--------|------------|--------------|----------|----------|
| **Context/Role** | âœ… | âœ… | âœ… | âš ï¸ (comment only) |
| **Markdown Headings** | âœ… | âœ… | âœ… | âš ï¸ |
| **JSON Blocks** | âœ… | âœ… | âœ… | âš ï¸ |
| **Long Prompts** | âš ï¸ | âœ… | âœ…âœ… | âŒ |
| **Inline Tasks** | âš ï¸ | âš ï¸ | âš ï¸ | âœ…âœ… |

---

## ðŸ§­ Final Note
> The *logic* of a prompt is universal â€” the *syntax* must adapt to the modelâ€™s input channel.

- Chat models â†’ favor **Markdown & structure**
- Code assistants â†’ favor **concise comments**
- Documentation generators â†’ favor **clarity & brevity**
